# 机器学习

# 如何机器学习
![机器学习](https://images0.cnblogs.com/blog/489652/201503/011004064867617.png)

## 分类
有监督学习：数据集包含数据和标签，得到一个可以将数据映射到标签的函数，例如：回归和分类  
强化学习：数据集包含数据和评分，尽可能让机器选择高分，例如:alpha go  
半监督学习：利用少量的标注样本和大量的未标注样本（标注成本高）进行训练，不需要人工干预  
无监督学习：数据集没有标签，得到数据之间某些关系，例如：聚类   

## 方式
离线（批量）：先训练，再用模型，不训练完就不用模型
在线：随着实时数据的到达，模型会在操作中不断地更新
主动：类似半监督学习，但需要一个外在的能够对其请求进行标注的实体，主动学习是交互进行

## 基本概念

### 模型
通过优化算法去学习到的由输入到输出的函数

## 错误衡量
衡量模型好坏，错误衡量越小，表明模型拟合数据集效果越好  
错误衡量的选取与P(Y|X)和计算错误的方法有关，一般我们使用逐点错误衡量（计算每个点上的错误度，把这些错误度加起来）的方式进行错误衡量，具体有0/1错误、平方错误等

### 0/1错误
对两种类型的错误平等处罚，用于平衡分类，但是这是一个NP问题，因此需要转化，例如交叉熵

### 平方错误
用于回归，最小化高斯噪音

## 梯度下降算法
类似贪心算法，从一点走梯度的反方向，可能得到局部最优解，而非全局最优解
$$
\theta_j = \theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta)
$$

## 数据集
- 训练集：主要是用来训练模型的
- 验证集：确定网络结构或者控制模型复杂程度的参数
- 测试集：检验最终选择最优的模型的泛化能力

对于小数据量(十万以下)6：2：2，大数据量(百万以上)98：1：1

## 评价指标
[准确率、精确率、召回率、F1值](https://blog.csdn.net/u013063099/article/details/80964865)，由此可以对两种类型的错误不平等处罚，用于不平衡分类

## 熵
对一个随机事件的概率分布进行预测时，预测应当满足全部已知的约束，而对未知的情况不要做任何主观假设。  
[熵](https://www.zhihu.com/question/22178202)是随机变量不确定性的度量，不确定性越大，熵值越大，[最大熵](https://blog.csdn.net/june_young_fan/article/details/88698301)是对不确定度的无偏分配，最大似然估计则是对信息的无偏理解  

